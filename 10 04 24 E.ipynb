{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcd616-feca-4ed5-89b5-c414d038ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import sklearn\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer, LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Activation\n",
    "from pandas import read_excel, DataFrame, Series\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from numpy.random import seed\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Загружаем первый датасет (базальтопластик) и посмотрим на названия столбцов\n",
    "df1 = pd.read_excel('/home/rw/myenv/VKR/X_bp.xlsx')\n",
    "df_bp.shape\n",
    "\n",
    "#Удаляем первый неинформативный столбец\n",
    "df_bp.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "#Посмотрим на первые 5 строк первого датасета и убедимся, что первый столбец удалился\n",
    "df_bp.head()\n",
    "\n",
    "# Проверим размерность первого файла\n",
    "df_bp.shape\n",
    "\n",
    "# Загружаем второй датасет (углепластик) \n",
    "df_nup = pd.read_excel('/home/rw/myenv/VKR/X_nup.xlsx')\n",
    "df_nup.shape\n",
    "\n",
    "#Удаляем первый неинформативный столбец\n",
    "df_nup.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "#Посмотрим на первые 5 строк второго датасета и убедимся, что и здесь не нужный первый столбец успешно удалился\n",
    "df_nup.head()\n",
    "\n",
    "# Проверим размерность второго файла\n",
    "df_nup.shape\n",
    "\n",
    "# Понимаем, что эти два датасета имеют разный объем строк. \n",
    "# Но наша задача собрать исходные данные файлы в один, единый набор данных. \n",
    "# По условию задачи объединяем их по типу INNER. \n",
    "df = df_bp.merge(df_nup, left_index = True, right_index = True, how = 'inner')\n",
    "df.head().T\n",
    "\n",
    "#Посмотрим количество колонок и столбцов\n",
    "df.shape\n",
    "# Итоговый датасет имеет 13 столбцов и 1023 строки, 17 строк из таблицы X_nup было отброшено,\n",
    "# т.е часть данных удалена на начальном этапе исследования.\n",
    "\n",
    "# Посмотрим на начальные и конечные строки нашего датасета на данном этапе работы\n",
    "df\n",
    "\n",
    "#Просмотрим информацию о датасете, проверим тип данных в каждом столбце (типы признаков)\n",
    "df.info()\n",
    "# все переменные содержат значения float64, качественные характеристики отсутствуют. Пропусков не имеется.\n",
    "# Ни одна из записей не является NaN, очистка не требуется. Объединенный файл имеет всего 1023 строки.\n",
    "\n",
    "#Поиск уникальных значений с помощью функции nunique\n",
    "df.nunique()\n",
    "#Видим в основном общее число уникальных значений в каждом столбце, но в столбце \"Угол нашивки\" всего 2 значения. Поработаем с ним. \n",
    "\n",
    "# Поработаем со столбцом \"Угол нашивки\"\n",
    "\n",
    "df['Угол нашивки, град'].nunique()\n",
    "#Так как кол-во уникальных значений в колонке Угол нашивки равно 2, можем привести данные в этой колонке к значениям 0 и 1\n",
    "\n",
    "#Проверим кол-во элементов, где Угол нашивки равен 0 градусов\n",
    "df['Угол нашивки, град'][df['Угол нашивки, град'] == 0.0].count()\n",
    "\n",
    "# Приведем столбец \"Угол нашивки\" к значениям 0 и 1 и integer\n",
    "df = df.replace({'Угол нашивки, град': {0.0 : 0, 90.0 : 1}})\n",
    "df['Угол нашивки, град'] = df['Угол нашивки, град'].astype(int)\n",
    "\n",
    "#Переименуем столбец\n",
    "df = df.rename(columns={'Угол нашивки, град' : 'Угол нашивки'})\n",
    "df\n",
    "\n",
    "#Посчитаем количество элементов, где угол нашивки равен 0 градусов и убедимся, что количество не изменилось после наших манипуляций\n",
    "df['Угол нашивки'][df['Угол нашивки'] == 0.0].count()\n",
    "#После преобразования колонки Угол нашивки к значениям 0 и 1, кол-во элементов,\n",
    "# где угол нашивки равен 0 не изменилось (520 до и после преобразования)\n",
    "\n",
    "# Переведем столбец с нумерацией в integer\n",
    "df.index = df.index.astype('int')\n",
    "\n",
    "# Сохраним итоговый датасет в отдельную папку с данными, чтобы долго не искать\n",
    "df.to_excel(\"Itog\\itog.xlsx\")\n",
    "\n",
    "#Изучим описательную статистику наших данных (максимальное, минимальное, квартили, медиана, стандартное отклонение, \n",
    "# среднее значение и т.д.), посмотрим на основные параметры анализа данных\n",
    "df.describe()\n",
    "\n",
    "a = df.describe()\n",
    "a.T\n",
    "\n",
    "# Пропуски данных\n",
    "\n",
    "# Проверим на пропущенные данные\n",
    "df.isnull().sum()\n",
    "# Пропущенных данных нет = нулевых значений нет, очистка не требуется\n",
    "\n",
    "#светло-зеленый - не пропущенные, темнозеленый - пропущенные данные\n",
    "cols = df.columns\n",
    "colours = ['#ceff1d', '#008000'] \n",
    "sns.heatmap(df[cols].isnull(), cmap = sns.color_palette(colours))\n",
    "#Тепловая карта, так же как info() и функция ISNULL() показывает, что пропусков нет.\n",
    "\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "#Дубликаты\n",
    "\n",
    "# Проверим датасет на дубликаты\n",
    "df.duplicated().sum()\n",
    "#Дубликатов нет\n",
    "\n",
    "#По заданию необходимо получить среднее, медианное значение для каждой колонки\n",
    "#среднее значение\n",
    "\n",
    "#получим среднее и медианное значения данных в колонках\n",
    "mean_and_50 = df.describe()\n",
    "mean_and_50.loc[['mean', '50%']]\n",
    "#в целом мы видим близкие друг к другу значения\n",
    "\n",
    "# среднее значение\n",
    "\n",
    "df.mean()\n",
    "\n",
    "# медианное значение\n",
    "\n",
    "df.median()\n",
    "\n",
    "# Вычисляем коэффициенты ранговой корреляции Кендалла. Статистической зависимости не наблюдаем.\n",
    "df.corr(method = 'kendall')\n",
    "\n",
    "#Вычисляем коэффициенты корреляции Пирсона. Статистической зависимости не наблюдаем.\n",
    "df.corr(method ='pearson')\n",
    "\n",
    "#Создадим переменную для названия всех столбцов. Это нам пригодится при построении моделей. И перейдем к визуализации данных\n",
    "df.columns\n",
    "#column_names = [\"Соотношение матрица-наполнитель\",\"Плотность, кг/м3\",\"модуль упругости, ГПа\",\"Количество отвердителя, м.%\",\n",
    "#         \"Содержание эпоксидных групп,%_2\",\"Температура вспышки, С_2\",\"Поверхностная плотность, г/м2\",\n",
    "#         \"Модуль упругости при растяжении, ГПа\",\"Прочность при растяжении, МПа\",\"Потребление смолы, г/м2\",\n",
    "#        \"Угол нашивки, град\",\"Шаг нашивки\",\"Плотность нашивки\"]\n",
    "column_names = df.columns\n",
    "\n",
    "# Построим гистограммы распределения каждой из переменных без нормализации и исключения шумов\n",
    "df.hist(figsize = (20,20), color = \"g\")\n",
    "plt.show()\n",
    "\n",
    "# Гистограмма распределения (второй вариант)\n",
    "a = 5 # количество строк\n",
    "b = 5 # количество столцбцов\n",
    "c = 1 # инициализация plot counter\n",
    "plt.figure(figsize = (35,35))\n",
    "plt.suptitle('Гистограммы переменных', fontsize = 30)\n",
    "for col in df.columns:\n",
    "    plt.subplot(a, b, c)\n",
    "    #plt.figure(figsize=(7,5))\n",
    "    sns.histplot(data = df[col], kde=True, color = \"darkgreen\")\n",
    "    plt.ylabel(None)\n",
    "    plt.title(col, size = 20)\n",
    "    #plt.show()\n",
    "    c += 1\n",
    "#Гистограммы показывают ярковыраженные выбросы в столбцах: плотность, содержание эпоксидных групп, температура вспышки, плотность нашивки. \n",
    "#Данные стремятся к нормальному распределению практически везде, кроме угла нашивки, имеющим только 2 значения, с которым мы уже \n",
    "#поработали ранее. \n",
    "\n",
    "# гистограмма распределения и боксплоты (третий вариант)\n",
    "\n",
    "for column in df.columns:\n",
    "    fig = px.histogram(df, x = column, color_discrete_sequence = ['green'], nbins = 100, marginal = \"box\")\n",
    "    fig.show()\n",
    "\n",
    "for column in df.columns:\n",
    "    fig = px.box(df, y = column)\n",
    "    fig.show()\n",
    "\n",
    "# \"Ящики с усами\"(боксплоты) (первый вариант)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "plt.figure(figsize = (20, 20))\n",
    "plt.suptitle('Диаграммы \"ящики с усами\"', y = 0.9 ,\n",
    "             fontsize = 30)\n",
    "plt.boxplot(pd.DataFrame(scaler.transform(df)), labels = df.columns,patch_artist = True, meanline = True, vert = False, boxprops = dict(facecolor = 'g', color = 'y'),medianprops = dict(color = 'lime'), whiskerprops = dict(color=\"g\"), capprops = dict(color = \"black\"), flierprops = dict(color = \"y\", markeredgecolor = \"maroon\"))\n",
    "plt.show()\n",
    "\n",
    "# Ящики с усами (второй вариант)\n",
    "a = 5 # количество строк\n",
    "b = 5 # количество столцбцов\n",
    "c = 1 # инициализация plot counter\n",
    "\n",
    "plt.figure(figsize = (35,35))\n",
    "plt.suptitle('Диаграммы \"ящики с усами\"', y = 0.9 ,\n",
    "             fontsize = 30)\n",
    "for col in df.columns:\n",
    "    plt.subplot(a, b, c)\n",
    "    #plt.figure(figsize=(7,5))\n",
    "    sns.boxplot(data = df, y = df[col], fliersize = 15, linewidth = 5, boxprops = dict(facecolor = 'y', color = 'g'), medianprops = dict(color = 'lime'), whiskerprops = dict(color=\"g\"), capprops = dict(color = \"yellow\"), flierprops = dict(color=\"y\", markeredgecolor = \"lime\"))\n",
    "    plt.ylabel(None)\n",
    "    plt.title(col, size = 20)\n",
    "    #plt.show()\n",
    "    c += 1\n",
    "# \"Ящики с усами\" показывают наличие выбросов во всех столбцах, кроме углов нашивки, значит, с ними будем работать\n",
    "\n",
    "# Гистограмма распределения и диаграмма \"ящик с усами\" вместе с данными по каждому столбцу\n",
    "for column_name in column_names:\n",
    "    print(column_name)\n",
    "    \n",
    "    #Гистограмма распределения\n",
    "    gis = df[column_name]\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.kdeplot(data = gis, shade = True, palette ='colorblind', color = \"g\")\n",
    "    plt.show()\n",
    "    \n",
    "    #Диаграмма \"Ящик с усами\"\n",
    "    sns.boxplot(x=gis, color = \"g\");\n",
    "    plt.show()\n",
    "    \n",
    "    #Значения (мин макс ср)\n",
    "    print(\"Минимальное значение: \", end = \" \")\n",
    "    print(np.min(gis))\n",
    "    print(\"Максимальное значение: \", end=\" \")\n",
    "    print(np.max(gis))\n",
    "    print(\"Среднее значение: \", end = \" \")\n",
    "    print(np.mean(gis))\n",
    "\n",
    "    print(\"Медианное значение: \", end = \" \")\n",
    "    print(np.median(gis))\n",
    "    print(\"\\n\\n\")\n",
    "# Кроме \"Угол нашивки, град\" и \"Поверхностная плотность, г/м2\" остальные переменные относительно хорошо соответствуют\n",
    "# нормальному распределению\n",
    "\n",
    "# Попарные графики рассеяния точек (матрица диаграмм рассеяния) (первый вариант)\n",
    "sns.set_style('darkgrid')\n",
    "sns.pairplot(df, hue = 'Угол нашивки', markers = [\"o\", \"s\"], diag_kind = 'auto', palette='YlGn')\n",
    "# Попарные графики рассеяния точек так же не показывают какой-либо зависимости между данными. Зависимость между показателями не линейная,\n",
    "# взаимосвязь отсутствует, необходимо использовать несколько показателей. \n",
    "# из графиков можно наблюдать выбросы, потому что некоторые точки располагаются далеко от общего облака\n",
    "# Отсутствие линейной корреляции наверняка подтвердится при построении регрессии?\n",
    "\n",
    "# Попарные графики рассеяния точек - скаттерплоты (второй вариант) \n",
    "g = sns.PairGrid(df[df.columns])\n",
    "g.map(sns.scatterplot, color = 'darkgreen')\n",
    "g.map_upper(sns.scatterplot, color = 'darkgreen')\n",
    "g.map_lower(sns.kdeplot, color = 'darkgreen')\n",
    "plt.show\n",
    "# Корреляции нет\n",
    "\n",
    "# график qq\n",
    "for i in df.columns:\n",
    "    plt.figure(figsize = (6, 4))\n",
    "    res = stats.probplot(df[i], plot = plt)\n",
    "    plt.title(i, fontsize = 10)\n",
    "    plt.xlabel(\"Теоретические квантили\", fontsize = 10)\n",
    "    plt.ylabel(\"Упорядоченные значения\", fontsize = 10)\n",
    "    plt.show()\n",
    "\n",
    "#Визуализация корреляционной матрицы с помощью тепловой карты\n",
    "mask = np.triu(df.corr())\n",
    "# Создаем полотно для отображения большого графика\n",
    "f, ax = plt.subplots(figsize = (11, 9))\n",
    "# # Визуализируем данные кореляции и создаем цветовую палитру\n",
    "sns.heatmap(df.corr(), mask = mask, annot = True, square = True, cmap = 'YlGn')\n",
    "plt.xticks(rotation = 45, ha='right')\n",
    "plt.show()\n",
    "# Максимальная корреляция между Плотностью нашивки и углом нашивки и составляет 0.11, что говорит об отсутствии зависимости между\n",
    "# этими данными. \n",
    "# Корреляция между всеми параметрами очень близка к 0, что говорит об отсутствии корреляционных связей между переменными.\n",
    "\n",
    "# График корреляции подтверждает данные теории композитных материалов. Мы видим, что на качество материла влияет температура вспышки\n",
    "# и количество отвердителя из-за взаимодействия отвердителя с матрицей и наполнителем под влиянием температуры.\n",
    "# Угол нашивки и плотность нашивки несомненно оказывают влияние на свойства материала. А потребление смолы \n",
    "# и соотношение матрицы-наполнителя, плотности и плотности нашивки, модуля упругости и плотности нашивки имеют не особенно\n",
    "# выраженную корреляцию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55bde4-7054-4bcb-94d7-0a0c70e42978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5a4bb-4fef-402b-a973-6b33dfcd0d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
